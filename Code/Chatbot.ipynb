{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98876bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3e0a6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d15d8b8d6454b79b63b04336ad440ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bc3fc1c8fa40a197b834ff4bdf70a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76af6ef52032447d86c90816271da657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc216298c95c42a1bc1024a2f01231d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4209882a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699331f7b88844e4b2e2b621347c9255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e78c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.base_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b2aaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.base_model.parameters() if p.requires_grad)    \n",
    "pytorch_trainable_params = sum(p.numel() for p in model.base_model.parameters() )    \n",
    "print(\"Total number of params\", pytorch_total_params)\n",
    "print(\"Total number of trainable params\", pytorch_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad05592",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r\"\"\"Japan is the eleventh-most populous country in the world, as well as one of the most densely populated and urbanized.\n",
    " About three-fourths of the country's terrain is mountainous, concentrating its population of 125.57 million on narrow coastal plains. \n",
    " Japan is divided into 47 administrative prefectures and eight traditional regions.\n",
    " Osaka has a big population of 16 million. \n",
    " The Greater Tokyo Area is the most populous metropolitan area in the world, with more than 37.4 million residents. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5ea8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_top_answers(possible_starts,possible_ends,input_ids):\n",
    "    answers = []\n",
    "    for start,end in zip(possible_starts,possible_ends):\n",
    "    #+1 for end\n",
    "        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[start:end+1]))\n",
    "        answers.append( answer )\n",
    "    return answers  \n",
    "\n",
    "def answer_question(question,context,topN):\n",
    "\n",
    "    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    \n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    model_out = model(**inputs)\n",
    "     \n",
    "    answer_start_scores = model_out[\"start_logits\"]\n",
    "    answer_end_scores = model_out[\"end_logits\"]\n",
    "\n",
    "    possible_starts = np.argsort(answer_start_scores.cpu().detach().numpy()).flatten()[::-1][:topN]\n",
    "    possible_ends = np.argsort(answer_end_scores.cpu().detach().numpy()).flatten()[::-1][:topN]\n",
    "    \n",
    "    #get best answer\n",
    "    answer_start = torch.argmax(answer_start_scores)  \n",
    "    answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "    answers = get_top_answers(possible_starts,possible_ends,input_ids )  #to extract only top related answers\n",
    "\n",
    "    return { \"answer\":answer,\"answer_start\":answer_start,\"answer_end\":answer_end,\"input_ids\":input_ids,\n",
    "            \"answer_start_scores\":answer_start_scores,\"answer_end_scores\":answer_end_scores,\"inputs\":inputs,\"answers\":answers,\n",
    "            \"possible_starts\":possible_starts,\"possible_ends\":possible_ends}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"How many states in Japan?\",\n",
    "    \"What is the population of Japan?\",\n",
    "    \"Which city is most crowded in the world?\",\n",
    "    \"What is the city with most population?\",\n",
    "    \"What is the topic here?\",\n",
    "    \"What are we talking about?\",\n",
    "    \"What is the main idea here?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7884de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in questions:\n",
    "    answer_map = answer_question(q,text,5)    \n",
    "    print(\"Question:\",q)\n",
    "    print(\"Answers:\")\n",
    "    [print((index+1),\" ) \",ans) for index,ans in  enumerate(answer_map[\"answers\"]) if len(ans) > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e7da72",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_map = answer_question(\"Where is most populous in the world?\",text,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"input_ids:\",answer_map[\"inputs\"][\"input_ids\"] )\n",
    "print(\"token_type_ids:\",answer_map[\"inputs\"][\"token_type_ids\"] )\n",
    "print(\"attention_mask:\",answer_map[\"inputs\"][\"attention_mask\"] )\n",
    "#answer_map[\"inputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363784c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len(answer_map[\"input_ids\"] ))\n",
    "tokenizer.decode( answer_map[\"input_ids\"] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e337b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_possible_answer(answer_map,expected_start,expected_end):\n",
    "    start_scores = answer_map[\"answer_start_scores\"]\n",
    "    end_scores = answer_map[\"answer_end_scores\"]\n",
    "    tokens = tokenizer.decode( answer_map[\"input_ids\"] ).split(\" \") \n",
    "    print(\"tokens\",len(tokens),\"---\",len(answer_map[\"input_ids\"]))\n",
    "    tokens_ind = [ tokenizer.decode(t) for t in answer_map[\"input_ids\"] ]\n",
    "    print(\"tokens_ind\",len(tokens_ind))\n",
    "    fig,axes = plt.subplots(2,1)\n",
    "    y_start = start_scores.detach().numpy().flatten()\n",
    "    x_start = [i for i in range(len(y_start))]\n",
    "\n",
    "    y_end = end_scores.detach().numpy().flatten()\n",
    "    x_end = [i for i in range(len(y_end))]\n",
    "\n",
    "    axes[0].bar(tokens_ind,y_start)\n",
    "    axes[0].set_title(\"start scores( \"+ str( len( y_start ) ) +\")\" )\n",
    "    axes[0].figure.set_size_inches(20, 5)\n",
    "    #axes[0].xaxis.set_labels( tokens_ind )\n",
    "    axes[0].xaxis.set_tick_params(rotation=90)\n",
    "    axes[0].axvline(expected_start,color=\"yellow\")\n",
    "\n",
    "    axes[1].bar(tokens_ind,y_end, color=\"orange\")\n",
    "    axes[1].set_title(\"end scores( \"+ str( len( y_end ) ) +\")\" )\n",
    "    axes[1].axvline(expected_end,color=\"red\")\n",
    "    axes[1].xaxis.set_tick_params(rotation=90)\n",
    "\n",
    "    axes[0].autoscale(tight=True)\n",
    "    axes[1].autoscale(tight=True)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9091622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_possible_answer(answer_map,10,11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
