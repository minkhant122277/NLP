{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd0c95e",
   "metadata": {},
   "source": [
    "### citation dataset: Banking77\n",
    "\n",
    "    @inproceedings{Casanueva2020,\n",
    "        author      = {I{\\~{n}}igo Casanueva and Tadas Temcinas and Daniela Gerz and Matthew Henderson and Ivan Vulic},\n",
    "        title       = {Efficient Intent Detection with Dual Sentence Encoders},\n",
    "        year        = {2020},\n",
    "        month       = {mar},\n",
    "        note        = {Data available at https://github.com/PolyAI-LDN/task-specific-datasets},\n",
    "        url         = {https://arxiv.org/abs/2003.04807},\n",
    "        booktitle   = {Proceedings of the 2nd Workshop on NLP for ConvAI - ACL 2020}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89995367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaConfig, RobertaModel, RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import AdamW\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from utils import create_supervised_pair, supervised_contrasive_loss, Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2bc77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f465e395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset banking77 (C:\\Users\\minkh\\.cache\\huggingface\\datasets\\banking77\\default\\1.1.0\\aec0289529599d4572d76ab00c8944cb84f88410ad0c9e7da26189d31f62a55b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8010c79680374439bc0fa6746f18ad65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('banking77')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dcd9641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 10003\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 3080\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a654613f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 10003\n",
      "})\n",
      "10003\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "print(train_dataset)\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76090ea",
   "metadata": {},
   "source": [
    "#### Split Train and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48067dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(train_dataset, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de089116",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I couldn't make a transfer because it was declined\", 'I have checked my statements multiple times, but my refund that I requested a while back is not showing on my account. Is there a reason for this? Can I get some help getting my money back from this transaction?', 'It seems my card payment was completed twice. I paid at the store previously and the first one did not seem to go through. After a second attempt, it did go through. I now see within the app that I have been charged twice with one of them pending. Can you please remove the pending amount because it is clearly something that was declined?']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76]\n"
     ]
    }
   ],
   "source": [
    "train_text = train[\"text\"]\n",
    "train_label = train[\"label\"]\n",
    "print(train_text[:3])\n",
    "print(sorted(set(train_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a75f723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I was not able to use the ATM to get cash', 'Do you support fiat currencies?', 'How do I get a PIN?']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76]\n"
     ]
    }
   ],
   "source": [
    "val_text = val[\"text\"]\n",
    "val_label = val[\"label\"]\n",
    "print(val_text[:3])\n",
    "print(sorted(set(val_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2dc48ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 10003\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dataset[\"test\"]\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84cea1b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How do I locate my card?', 'I still have not received my new card, I ordered over a week ago.', 'I ordered a card but it has not arrived. Help please!']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76]\n"
     ]
    }
   ],
   "source": [
    "test_text = test_dataset[\"text\"]\n",
    "test_label = test_dataset[\"label\"]\n",
    "print(test_text[:3])\n",
    "print(sorted(set(test_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20024df",
   "metadata": {},
   "source": [
    "#### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdf505b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTextDataset(Dataset):\n",
    "    def __init__(self,labels,text,batch_size,repeated_label:bool=False):\n",
    "        self.labels = labels\n",
    "        self.text = text\n",
    "        self.batch_size = batch_size \n",
    "        self.count = 0 \n",
    "        self.repeated_label = repeated_label        \n",
    "        # to use when training with supervise contrastive loss\n",
    "        if self.repeated_label == True:\n",
    "           # write the code here\n",
    "            self.exist_classes = [] \n",
    "            self.label_maps = None \n",
    "            self.ids_maps = []\n",
    "            self.len_data = len(self.labels)\n",
    "            self.count_batch = 0 \n",
    "            self.is_left_batch = False\n",
    "            #print(\"self.len_data \",self.len_data)\n",
    "            #print(\"self.len data\",self.batch_size)\n",
    "            self.max_count = self.len_data // self.batch_size \n",
    "            if self.len_data % self.batch_size !=0:\n",
    "                self.max_count += 1 \n",
    "            print(\"the number of maximum of batching :\",self.max_count)\n",
    "            pass\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # write code here for 1)\n",
    "        if self.repeated_label == True:\n",
    "            self.count +=1  \n",
    "            # it would be clear after call til batch_size  \n",
    "            self.exist_classes.append(self.labels[idx])\n",
    "            self.ids_maps.append(idx)\n",
    "            if self.count_batch == self.max_count - 1:\n",
    "                self.count_batch = +1 \n",
    "                #print(\"self.count_batch :\",self.count_batch)\n",
    "                self.count_batch = 0 \n",
    "\n",
    "                if self.len_data % self.batch_size !=0: \n",
    "                    self.batch_size = self.len_data % self.batch_size\n",
    "                    self.is_left_batch = True\n",
    "                #print(\"change batch size !\",self.batch_size)\n",
    "                #print(\"LAST batching !\")\n",
    "            if self.count == self.batch_size:\n",
    "                unique_labels_keys = list(set(self.exist_classes))\n",
    "                table = [0] * len(unique_labels_keys)\n",
    "                unique_labels = dict(zip(unique_labels_keys,table))\n",
    "                if self.is_left_batch == True:\n",
    "                    self.is_left_batch = False\n",
    "                    self.batch_size = 16  \n",
    "                else: \n",
    "                    self.count_batch += 1\n",
    "                    #print(\"count_batch :\",self.count_batch)          \n",
    "                for class_key in self.exist_classes:\n",
    "                    unique_labels[class_key] = +1 \n",
    "                #print(\"tables of each labels :\",unique_labels)\n",
    "                for index, key  in enumerate(unique_labels):\n",
    "                    if unique_labels[key] > 1:\n",
    "                        print(\"v>1 :\",unique_labels[key])\n",
    "                        break\n",
    "                    if index == len(unique_labels.keys()) - 1:\n",
    "                        while True:\n",
    "                            pos_idx = random.randint(0,self.len_data-1) \n",
    "                            if self.labels[pos_idx] in unique_labels.keys():\n",
    "                                if self.labels[pos_idx] == self.labels[idx]:\n",
    "                                    pass\n",
    "                                else:\n",
    "                                   #print(\"old idx :\",idx,self.labels[idx])\n",
    "                                    idx = pos_idx\n",
    "                                   #print(\"new idx :\",idx,self.labels[idx])\n",
    "                                    unique_labels[self.labels[idx]] +=1  \n",
    "                                   #print(\"statistics tables :\",unique_labels)\n",
    "                                   # replace last token\n",
    "                                    self.exist_classes[-1] = self.labels[idx]\n",
    "                                    if len(set(self.exist_classes)) ==  len(self.exist_classes):\n",
    "                                        print(\"unique_labels:\")\n",
    "                                        #print(unique_labels)\n",
    "                                    self.count = 0  \n",
    "                                    self.exist_classes = [] \n",
    "                                    self.ids_maps = []\n",
    "                                    break \n",
    "\n",
    "        label = self.labels[idx]\n",
    "        data = self.text[idx]\n",
    "        sample = {\"Class\": label,\"Text\": data}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb2e5b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc3a116e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of maximum of batching : 2001\n",
      "the number of maximum of batching : 501\n",
      "the number of maximum of batching : 770\n"
     ]
    }
   ],
   "source": [
    "train_data = CustomTextDataset(train_label, train_text, batch_size = batch_size, repeated_label = True)\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "val_data = CustomTextDataset(val_label,val_text, batch_size = batch_size, repeated_label = True)\n",
    "val_loader = DataLoader(val_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "test_data = CustomTextDataset(test_label, test_text, batch_size = batch_size, repeated_label = True)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73bff10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
